# Cybersecurity Detection Project - BETH Dataset
![cyber_photo](https://github.com/user-attachments/assets/ae343826-7fe7-494c-8631-f6f0162ef695)

A machine learning project for detecting suspicious system events using neural networks implemented in PyTorch. This project analyzes process logs to classify events as suspicious or benign using the BETH Dataset.

## Project Overview

This project implements a binary classification model to detect suspicious system activities from process log events. Each log represents a snapshot of system activity that can be analyzed to identify potential cybersecurity threats. The model classifies system events as either suspicious (1) or benign (0).

## Dataset Information

**Source**: [BETH Dataset from Kaggle](https://www.kaggle.com/)  
**Paper**: "BETH Dataset: Real Cybersecurity Data for Anomaly Detection Research"

### Dataset Description
Each row represents a log event generated by a process running on a machine - essentially a snapshot of system activity at a specific point in time. These logs contain information that can assess whether the activity is suspicious.

### Features (7 columns)

| Column | Description | Type |
|--------|-------------|------|
| `processId` | Unique identifier for the process that generated the event. Useful for tracking activity related to specific processes | int64 |
| `threadId` | ID for the thread spawning the log. Some threats operate through specific threads to avoid detection | int64 |
| `parentProcessId` | Label for the process spawning this log | int64 |
| `userId` | ID of user spawning the log. Helps detect if a low-privileged user is performing admin-level actions | int64 |
| `mountNamespace` | Mounting restrictions the process log works within. Attackers sometimes exploit mount namespaces to hide files or isolate malicious actions | int64 |
| `argsNum` | Number of arguments passed to the event. Unusual numbers of arguments might indicate tampering or exploit attempts | int64 |
| `returnValue` | Value returned from the event log (usually 0). A return value of 0 indicates success. Unexpected or frequent failures may signal probing or brute-force attempts | int64 |

### Target Variable
| Column | Description | Type |
|--------|-------------|------|
| `sus_label` | Binary label for suspicious event (1 = suspicious, 0 = not suspicious) | int64 |

## Model Architecture

```python
model = nn.Sequential(
    nn.Linear(7, 64),      
    nn.ReLU(),
    nn.Linear(64, 32),
    nn.ReLU(),
    nn.Linear(32, 1),      
    nn.Sigmoid()          
)
```

### Model Specifications
- **Input Features**: 7 (all process log attributes)
- **Hidden Layers**: 64 → 32 neurons with ReLU activation
- **Output**: Single neuron with Sigmoid activation
- **Loss Function**: Binary Cross Entropy (BCELoss)
- **Optimizer**: SGD with momentum

```

## Project Structure

```deep-learning-threat-detection/
│
├── data/
│   ├── labelled_train.csv
│   ├── labelled_test.csv
│   └── labelled_validation.csv
│
├── notebooks/
│   └── notebook.ipynb
│
├── README.md
├── requirements.txt
└── .gitignore
```



## Important Note
- This project was undertaken to cement knowledge and get hands on after completing "Datacamp's Introduction to Pytorch", So it might not be as indepth.
